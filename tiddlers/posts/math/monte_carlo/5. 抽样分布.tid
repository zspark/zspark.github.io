created: 20190828121218136
creator: Jerry
modified: 20190919194505313
modifier: Jerry
tags: [[monte carlo]]
title: 5. 抽样分布
type: text/vnd.tiddlywiki

{{monte carlo}}


本章译者：余明慧

校验进行中：Jerry



! 抽样分布：统计数据 

本章主要描述了蒙特卡罗方法的一些重要概念。
本章提出的所有的方程式的数学证明都在下一章中。

 显然，我们无法计算一个无限总体的总体均值。（这样的总体可以被看作是例如用无限数量的硬币投掷得到的结果。当然，这个概念只是理论上的，这种总体只是假设存在。）但是即便是总体数量是有限的但非常大，计算它的平均值也是一个不切实际的任务。当面对以上这些情况时，我们可以从总体中抽取样本（其中每个样本都可以被看作是一个随机变量），并将这些抽取的随机变量的总和除以样本总数，得到我们所说的一个样本均值(sample mean)。这个数字是对总体均值的估计（而不是近似值）。在上一章中我们已经介绍过了这两个概念。

 在统计学中，对于一个给定的总体, 可以用这个总体的所有元素或项(items)计算出某些特征，我们称为计算得到的值是这个总体的一个参数(parameter)。例如，总体均值是一个总体参数，用于定义数量的平均值。参数是固定值。另一方面，当我们使用样本来得到总体参数的估计时，我们认为样本值是一个统计量（statistic）。参数通常被给予希腊字母，而统计量通常被赋予罗马字母。注意：因为从一个给定的总体中可能抽取出不止一个样本来，该统计量的值可能因样本不同而不同。

 我们计算均值或者方差的方法取决于是使用总体中的所有元素还是总体中的样本。下表显示了两种情况的差异：


注意：统计量的方差定义为（下标n表示从总体中抽取的元素的数量），将其与总体方差区分。方差的第二个方程式是非常有用的，因为从编程的角度，可以使用它来计算从总体中提取的元素的方差(而不是等待所有的样本)。既然我们已经明白了这两种情况的联系与不同(统计量是总体参数的一个估计)。接下来，我们用实际例子说明。
为了使演示更容易，我们编写了一个C++程序(见下面源代码)，生成一个由参数定义的元素组成的总体，该参数是0到20的整数(这与使用数字标记的卡片实验类似)。为了产生这个总体，我们随机地为0到20之间的每一个数字拾取1到50之间的数字。该数字表示总体中具有特定值(0-20)的元素的数量。总体数量就是这些值的总和。这个总体的参数（总体总数，总体均值和方差）如下表所示：



程序的其余部分将对这个总体进行1000次的抽样，其中样本的大小（从总体中抽取的元素数量用于计算样本均值和方差）将在2到20之间变化。这将有助于我们看到采样技术对少和多数量的样本有何不同。对于每次抽取，我们随机选择一个样本大小n，然后从总体中抽取n个样本，我们首先从总体中随机选择一项(1到总体总数之间的随机数)。

```cpp
 //The process by which we find out the value held by this item is a bit unusual. 我们从项目索引中逐渐减去持有特定值(从0开始，然后1，。。。)的项目数。一旦项目索引小于0，中断循环。
 int item_index  pick_item_distr(rng), k;
 for (k  0; k < MAX_NUM; ++k) { 
  	item_index - population[k]; 
    if (item_index < 0) break; 
 }
```

当我们中断循环时，k表示所选元素所持有的值。该抽样的工作原理是：随机选择抽取的元素的索引（也就是，选择1组中的元素的可能性与2组，3组...中的一样）。


 (As the elements are drawn from the population we update the variables used for computing the sample mean and the sample variance. )由于元素是从总体中抽取的，我们计算出用于计算样本均值和样本方差的变量。最后，我们得到了1000个样本集和与它们相关联的样本均值和方差。绘制这些结果将有助于我们对从总体中抽取样品的过程中得到一些有趣的结论。注意：图1中，小尺寸的样本集被绘制为红色，而大尺寸的样本集被绘制成蓝色。当样本集的大小在2和20之间时，样本颜色在红蓝之间插入。图中绿点表示图上的总体参数(均值和方差)重合的点。任何接近这个点的样本都可以被认为是对总体均值和方差的一个很好的估计。离这个点越远，估计越差。

 如果你仍然很难理解图1中的样本(或统计量)的位置，则看第二个简单的例子，其中我们绘制了9个人的体重。如果我们要测量总体重量的均值，我们将在这条线(在相关图像中标记总体均值)中间的某个地方获得一些值。现在考虑一下，从这个总体集合中抽样，我们将得到右边3个红圈圈的样本集。正如你看到的，从这3个样本集计算的样本均值与总体均值有很大不同。现在考虑样本中的绿色圈出来的那个。（我觉得此处红绿色写反了）另一方面，取这些样本的平均给出了总体均值的良好估计。样本集合以及他们是如何“随机分布”的代表总体每项的所有可能组合的一个子集(The set of samples and how "randomly" distributed they are represents a subset of all the possible combinations of items from the population.这句词语组合不好 )。样本的传播方式取决于(正如我们将很快看到的)一些因素，比如样本量的大小和总体本身的分布。


下面是图1的源代码：

```cpp
#include <random> 
#include <cstdlib> 
#include <cstdio> 
 
static const int MAX_NUM  20;  // items in the population are numbered (number between 0 and 20) 
static const int MAX_FREQ  50; // number of items holding a particular number varies between 1 and 50 
 
int main(int argc, char **argv) 
{ 
    int minSampples  atoi(argv[1]); // minimum sample size 
    int maxSampples  atoi(argv[2]); // maximum sample size 
    std::mt19937 rng; 
    int population[MAX_NUM + 1]; 
    int popSize  0; 
    float popMean  0; 
    float popVar  0; 
    static const int numSamples  1000; 
 
    rng.seed(17); 
 
    // creation population
    std::uniform_int_distribution<uint32_t> distr(1,MAX_FREQ); 
 
    for (int i  0; i < MAX_NUM; ++i) { 
        population[i]  distr(rng); 
        popSize + population[i]; 
        popMean + population[i] * i; // prob * x_i 
        popVar + population[i] * i * i; // prob * x_i^2 
    } 
 
    popMean / popSize; 
    popVar / popSize; 
    popVar - popMean * popMean; 
    fprintf(stderr, "size %d mean %f var %f\n", popSize, popMean, popVar); 
    std::uniform_int_distribution<uint32_t> n_samples_distr(minSampples, maxSampples); 
    std::uniform_int_distribution<uint32_t> pick_item_distr(0, popSize - 1); 
 
    float expectedValueMean  0, varianceMean  0; 
    // now that we have some data and stats to work with sample it
    for (int i  0; i < numSamples; ++i) { 
        int n  n_samples_distr(rng); // sample size 
        float sample_mean  0, sample_variance  0; 
        // draw samples from population and compute stats
        for (int j  0; j < n; ++j) { 
            int item_index  pick_item_distr(rng), k; 
            for (k  0; k < MAX_NUM; ++k) { 
                item_index - population[k]; 
                if (item_index < 0) break; 
 
            } 
            // k is the value we picked up from population, 
            // this is the outcome a number between [0:20]
            sample_mean + k; 
            sample_variance + k * k; 
        } 
        sample_mean / n; 
        sample_variance / n; 
        sample_variance - sample_mean * sample_mean; 
 
        float c1[3]  { 1, 0, 0 }; 
        float c2[3]  { 0, 0, 1 }; 
        float t  (n - minSampples) / (float)(maxSampples - minSampples); 
        float r  c1[0] * (1 - t) + c2[0] * t; 
        float g  c1[1] * (1 - t) + c2[1] * t; 
        float b  c1[2] * (1 - t) + c2[2] * t; 
        printf("sample mean: %f sample variance: %f col: %f %f %f;\n", sample_mean, sample_variance, r, g, b); 
    } 
 
    return 0; 
} 
```

我们可以通过这个图得到什么？首先，沿着横坐标(x)和纵坐标(y)看图。样本均值线(垂直的青色线)附近的任何样本都可以被认为是对总体均值的一个很好的估计。任何靠近总体方差线(水平的青色线)的样本都提供了对总体方差的一个很好的估计。然而，真正的“好”样本集是同时接近这两条线的。我们已经在图1中说明了黄色部分表示绿点附近的一些样本，由于它们相当接近这两个参数，所以被认为是很好的样本(如果你对此有兴趣，read about confidence interval)。还要注意，这个集群中大多数样本集都是蓝色的，但并不全部都是（仍然有一小部分红色的）。这个告诉我们，样本量越大，我们越有可能得到收敛到总体参数的一个估计。请注意，我们说的是“我们更有可能”，我们没有说样本量越大估计越好。这实际上是统计学和近似这个概念之间的差异(多么微妙和哲学)。在统计学中，总有可能(即使非常小)从样本得到的值与总体参数完全相同。无论多么不可能，无论样本量大（或小），都存在这种机会。然而，一个样本量非常小的样本比样本量更大的样本更有可能得到一个偏离的估计，即使样本估计更可能收敛到总体参数。

 Note 1: 的确，通过大数定律(law of large numbers我们在第2章已经说过)，当n趋于无穷大的时候，样本均值概率收敛（converge in probability），几乎肯定地达到预期值。

 注意：我们在上面的定义中使用了“几乎”。我们不能肯定的预测它将会收敛，但是我们可以说随着样本量的增加，它的概率会越来越高。这完全是关于概率的。
图2展示了随着样本量的增加，样本的“质量”会发生什么变化。样本仍然分布在总体均值和方差周围，但是样本集群的缩小确实表明了估计的质量平均比图1中的要好。换句话说，随着n的增加，样本集群越来越小(表示估计质量的总体改
善)，你也可以说，随着n增加，统计数据越来越集中在某一值(some value)。接下来有两个问题，这个值是什么？当n接近于无穷时，这些统计数据将会发生什么变化？但是，当我们引入大数定律(Law of Large Numbers)时，已经给出了这些问题的答案。这个值就是总体均值，当n趋于无穷大时，样本均值接近总体均值。请记住有关期望值(Expected Value)这章中这些定义：


如图3所示，我们程序生成的总体具有任意分布。这个总体既不是任何特定的概率分布也不是正态分布。我们很快就会清楚为什么这样做。因为分布是离散和有限的，所以这个总体具有明确的均值和方差（我们已经在上面计算过了）。我们现在要做的是从这个总体中抽取大小为n的样本，计算它们的平均值，并重复该实验1000次。样本均值将四舍五入为最接近的整数值(它在0到20之间的任何整数值)。这个结束后，我们将会计算一下样本的数量，它们的均值是0-20之间。图4显示了结果。显而易见，样本的分布服从正态分布。我们正在研究的不是卡片的分布而是样本的分布。一定要明白这两个的区别。这是统计数据的分布(distribution of statistics)。还要注意的是，这不是一个完全正态分布（上一章已经说明），因为很显然，结果和完全正态分布(红色曲线)之间有些差异。总而言之，即使总体分布是任意的，样本或者统计数据的分布不是任意的（它的分布趋近于正态分布上，稍后我们回到这个这里）。

读者问题(Question from a reader)：你是基于什么声称抽样分布不是完全正态分布？并且如何使曲线(图4中的红色曲线)贴近你的数据？我们知道一个正态分布是由一个数学方程定义的，两个参数分别是均值和标准差(参见上一章)。从计算的角度看，我们可以测量抽样分布的偏斜(skew)和峰度(kurtosis)(但是我们这里没有介绍)。如果这两个参数中的任何一个都不为零，那么我们可以肯定我们的抽样分布不是一个完全正态分布（参见前面的章节）。对于第二个问题，可以计算样本的期望和它们的标准差(我们下面会讲如何计算)，根据这些数字我们可以绘制出一个如图4所示的曲线。请记住，这条曲线并不重要。重要的是样本和它的抽样分布。你可以认为曲线显示的是抽样分布的总体趋势(tendency of the sampling distribution)。

以下代码用于计算图4中的数据

```cpp
int main(int argc, char **argv) 
{ 
    ... 
 
    int meansCount[MAX_NUM + 1]; 
    for (int i  0; i < MAX_NUM; ++i) meansCount[i]  0; 
 
    // now that we have some data and stats to work with sample it
    for (int i  0; i < numSamples; ++i) { 
        ... 
        meansCount[(int)sample_mean]++; 
    } 
 
    for (int i  0; i < MAX_NUM; ++i) printf("%d %d\n", i, meansCount[i]); 
    ... 
} 
```

我们重复了很多次，样本均值和样本方差是自己的随机变量(每个样本可能具有与其他样本不同的值)，因此像其他随机变量一样，我们可以研究它们的概率分布。换句话说，我们不是研究一个特定国家（总体）所有成年人的身高（财产）如何分布，而是从这个总体中抽取样本来估计总体的平均身高，然后看看这些样本之间是如何分布的。在统计学中，样本
(或统计)的分布称为抽样分布(sampling distribution)。类似于总体分布，可以使用模型(比如概率分布probability distributions)来定义抽样分布。它定义了对于一个给定的总体群体和给定大小的所有可能的样本是如何分布的。

Note 2: 当从一个大小为n的随机样本中导出的时候，一个统计量的抽样分布是该统计量的分布，它被视为一个随机变量。换句话说，均值的抽样分布是样本均值的分布。

请记住：自己的统计量是一些随机变量的一个函数，因此它本身就是一个随机变量。和其他随机变量一样，它也有一个分布。这个分布就是我们所说的统计量的抽样分布。统计量的值和抽取这些值中的任意一个的可能性取决于统计量的概率分布。

从定义中得出很重要的一点，如果你知道某些统计量的抽样分布，那么在观察数据之前，你可以求出在某些值上的概率。

下一个概念就是我们目前所用到的一个扩展。记住在第1章中我们学习了如何计算期望值。在离散随机变量的情况下（对于连续的r,v，概念是相同的，但是使用离散的r.v.来描述概念更容易），我们知道期望值或者均值不过是其每个结果的概率加权总和。

Note 3：正如总体可以用诸如均值等参数所描述的那样，抽样分布也是如此。换句话说，我们可以用相同的方法来计算样本或统计量的均值而不是用计算随机变量的均值的方法。对于样本，得到的值称为均值分布的期望（expected value of the distribution of mean），定义为：

其中表示样本均值的概率，且这些概率本身是抽样分布的。当以相同的概率(即均匀分布)绘制样本时，概率仅为，其中表示样本集中的数量或统计数量(而不是样本的大小)( the number of samples or statistics (not the sample size))。

由于超出本课程范围的原因，与均值不能认为是完全一样的（因为当样本大小接近无穷大时，这个值是未定义的），但是它可以被解释或看作是类似于它的东西。均值分布的期望值从某个角度可以被看作是有限数量的样本均值的加权平均数(weighted average )。不是平均值，是加权平均数（权重就是每个可能的结果的频率或概率）：


这个式子跟上面的一样，不过我们用替换了；但是在本文中，这两个意思是一样的。

可以证明：均值分布的期望与总体均值相等：，证明过程见本章末尾(参见样本均值的属性)。但是，就现在来看，在统计学上，当一个统计量（比如）的期望等于总体参数时，这个统计量本身被称为该参数的无偏估计量(unbiased estimator)。例如，我们可以说是的无偏估计。在下一章中，我们将再次对这个重要概念进行详细的回顾。我们还将在蒙特卡罗章节介绍蒙特卡罗是一个（无偏）估计。

如果现在增加样本大小(即增加)，那么样本更有可能给出对总体均值的更好的估计（我们已经在图2中说明了这个结果）。并非所有的样本都接近于均值，但是一般来讲，样本大小()越高越接近均值。样本的分布与以前情况一样，具有正态分布。但是如果比较图3和图4，则可以看出第二个分布比第一个分布更加紧密。随着增加，你更接近于使用总体中所有的元素来估计均值。因此，在逻辑上，样本均值就更有可能接近总体均值（或者换句话说，样本均值远离总体均值的机会更小）。该实验展示了图1和图2中某些相似的东西，也就是样本大小越大我们越有可能趋于真实均值（即总体均值）。我们可以很容易的观察，
当我们增加样本容量时，均值分布的期望值（以及相关的标准偏差也叫均方差standard deviation）的变化的实验来验证这个结论。我们应该预想到样本均值的期望收敛到总体均值并且正态分布(用它的标准偏差来衡量)随着样本大小的增大而更加紧密。下面代码是来计算这2个变量的，即expectedValueDistrMeans（相当于） 和varianceDistrMeans （相当于）。代码中，每个样本具有相同的样本大小（第6行），我们还从总体中增加了样本量总数（第4行）来提高估计的鲁棒性(从1000增加到10000样本)。



```cpp
int main(int argc, char **argv) 
{ 
    ... 
    static const int numSamples  10000; 
    ... 
    float expectedValueDistrMeans  0, varianceDistrMeans  0; 
    for (int i  0; i < numSamples; ++i) { 
        int n  atoi(argv[1]); // fix sample size 
        float sample_mean  0, sample_variance  0; 
        for (int j  0; j < n; ++j) { 
            ... 
        } 
        sample_mean / n; 
        sample_variance / n; 
        sample_variance - sample_mean * sample_mean; 
        meansCount[(int)(sample_mean)]++; 
 
        expectedValueDistrMeans + sample_mean; 
        varianceDistrMeans + sample_mean * sample_mean; 
    } 
    expectedValueDistrMeans / numSamples; 
    varianceDistrMeans / numSamples; 
    varianceDistrMeans - expectedValueDistrMeans * expectedValueDistrMeans; 
    fprintf(stderr, "Expected Value of the Mean %f Standard Deviation %f\n", expectedValueDistrMeans, sqrt(varianceDistrMeans)); 
 
    return 0; 
} 
```

还好吗？有读者告诉我们，他们已经迷失方向了。他们真的不理解我们在计算什么。一般都是统计学中的问题，因为它们的名字本身就令人很困惑。例如：当我们谈到均值的抽样分布的均值时，你需要花点时间来理解我们所说的。为了清晰明了，我们想出了下图：

首先，从一个总体开始，然后你随机抽取这个总体中的元素。在这个特定的图表中，每一个实验我们都做了3个观察（in each experiment we make what we call 3 observations这里应该就是每个实验取了3个个体，用观察不太好，也想不出啥词好了），换句话说，我们从总体中抽取了3
项，应该是每组做了3次试验(we draw 3 items from the population)。因为它们都是随机变量，我们用小写字母来标记实验中可能的结果。如果现在就对这3项取加权平均，我们就得到了大小为的样本或统计量。为了计算样本的值，我们使用期望值公式(或均值)。每个样本都是一个随机变量，但因为现在他们代表的是总体中某n项(n是确定数)的均值，我们用大写字母来表示。我们可以重复这个实验N次，将会得到一系列的样本：，，...，。这些样本的集合就是我们说的抽样分布。因为样本是随机的，因此我们可以计算出它们的均值就像我们计算总体中的均值一样。这就是我们所说的均值的抽样分布的期望（或者均值），定义为。一旦我们有了这个值，我们就可以计算均值的分布的方差。


我们每次都运行这个程序好几次，每次把样本的大小增加2倍。结果如下表（记住程序中计算出来的总体均值：8.970280）：



首先，数据似乎证明了这一理论。随着样本大小的增加，我们所有样本的均值接近总体均值(即8.970280)。此外，均值分布的标准偏差随着预期而减少(你可以认为正态分布的曲线变窄了)。因此，综上所述，随着n接近无穷大，抽样分布变成均值和标准偏差0：完全正态分布：。我们说随机变量，，...，的随机序列收敛于正态分布。

尝试将分布收敛的概念与概率收敛的概念(在Expected Value这一章中介绍过)相联系。

这很重要，因为数学家喜欢有证据证明最后样本的均值与总体均值是相等的，并且该方法是有效的(从理论角度看，因为明显地，在实际中，样本大小不可能是无限的)。换句话说，我们可以写（通过实验检查了这个结果）：


如果你不太在乎数学，只想了解这是如何应用于你（渲染领域），你可以看到“因为你继续抽取样本(即n增加)，你的估计越来越好”。最终你有这么多样本，你的估计和你想要估计的值是非常接近的，甚至当你有无限大的样本时，在理论上是一样的。这就是真的“均值”。

现在让我们来谈一些在统计学上非常重要的东西，但更重要的是渲染（至少对我们有用的东西）。如果再次查看表格，你可能已经注意到了当N2和N16(8.9608 - 8.9289  0.0319)时，均值分布的期望值之间的差异大于N32和N16384(8.9703 - 8.9658  0.0045)时。换句话说，从32到16384个样本的估计只比从2到16个样本更好一点（精确值是0.0319/0.0045）。

当你不断增加样本大小n时，我们将在章节末尾证明这个关系，均值分布的方差根据下面式子计算：


其中表示总体的标准差，n表示样本大小。换句话说，均值分布的标准偏差(你可以将其解释为总体均值估计的误差，实际上，在统计学中，均值分布的标准差称为标准误差standard error)随着样本的大小 减少而减小的速率是非线性的(根号运算是非线性的)。我们可以认为收敛速度是（你可以将其看作算法的性能与n的平方根成正比）。注意：在统计学中，方差也称为均方误差（Mean Squared Error），由于方差是标准差的平方根，所以它随
n的变化而线性变化。
这种关系的结果是需要四倍的样本将估计误差减少一半。当我们到蒙特卡罗章节时，我们将回到这个结论。

接下来的结果有助于更好的理解“需要四倍的样本将估计误差减少一半”。假设总体的标准偏差是1，开始时，你的样本大小是4，因此你的标准误差是。现在你想要将误差减少2倍，则需要4倍的样本，即16个样本。计算一下：，这是正确的。接着，如果你想再次减少这个误差，你需要4次16个样本，就是64个样本：。注意：处理时间随着样本大小的增加而线性增加，因此4倍的样本大小增加了4倍的处理时间（假设样本大小与处理时间之间呈现线性关系，这是一个合理的假设）。这应该会让你直观地理解为什么蒙特卡罗方法会很快变得昂贵。你可以在图5中看到这条收敛速度的曲线。从实际角度来看，这意味着，甚至在你的估计上做一点小小的改动，它就会快速的变得非常昂贵。但是另一方面，这个方法给出了在样本量相对较少时候的相对较好的估计。这个关系的证明将在下一章节中给出，但是我们可以通过实验来测试。我们修改了程序，打印出根据样本计算出的标准误差和根据等式计算的标准误差，并运行不同的样本大小的程序。

```cpp
int main(int argc, char **argv) 
{ 
    ... 
    int n  atoi(argv[1]);//n_samples_distr(rng); // sample size 
    for (int i  0; i < numSamples; ++i) { 
        ... 
        for (int j  0; j < n; ++j) { 
            ... 
        } 
        expectedValueMean + sample_mean; 
        varianceMean + sample_mean * sample_mean; 
    } 
    expectedValueMean / numSamples; 
    varianceMean / numSamples; 
    varianceMean - expectedValueMean * expectedValueMean; 
    fprintf(stderr, "Std Err (theory): %f Std Err (data): %f\n", sqrtf(popVar) / sqrtf(n), sqrt(varianceMean)); 
 
    return 0; 
} 
```

结果见下表，毫无疑问，从样本中计算出的标准误差与方程得出的值紧密匹配。


所有这些工作都运用了数学上的中心极限定理(CTL)（它被认为是统计学甚至是数学中最重要的概念之一，大多数抽样理论都是基于这一理论）。

中心极限定理表明均值的抽样分布的均值等于总体的均值，并且均值分布的标准误差等于总体标准方差除以。此外，均值的抽样分布将会接近正态分布。这个关系可以概括如下：

同样，这个定理适用于：即使我们对总体分布没有任何了解，如果我们有足够的样本，则样本均值的分布也总是接近正态分布（假设样本是独立同分布）。

对于好奇的读者：你可能会在统计数据中遇到“渐进分布”一词。这是一个高级课题，我们将在单独的课程中研究，但是我们将在这里给出一个简单的答案，就是说当n趋近无穷大，它是抽样分布收敛到的一个函数的术语。在样本均值上下文中，我们解释了当n趋近于无穷大时，抽样分布收敛于正态分布。因此，正态分布被认为是的渐近分布。事实上，将减去，再除以方差，然后整个式子再乘以，则将变成标准正态分布。我们可以说趋近于，即标准正态分布。

 样本均值的性质 

现在我们将复习样本均值的属性：


特别是给出样本均值的平均值和方差的证明。首先，让我们来回顾一下我们前面提到的样本均值的期望等于总体均值。


样本均值的期望是所有组成这个样本均值的随机变量的期望的平均值，为了真正理解这个证明，你需要回到期望值的第一个和第二个属性（本章就可以找到）：

由于样本均值等于：，我们可以得到：

我们也知道随机变量的期望值就是总体均值，因此我们可以在式子中用代替。 The end of the demonstration is trivial. 你可以求得n个的和，或者n乘以总体均值。消去n然后留下（式子1）。现在我们来看一下样本均值的方差（式子2）：

这个证明，我们需要使用方差的第二和第三个属性（可以在本章中找到）：

有了这两个属性，推导很简单：

要完成证明，只需要用代替。对于样本均值，我们有n个，两个n相消，留下。最后我们可以得到标准差即方差的平方根就是。请注意：这个属性很有趣，因为它本质上表示样本均值的方差比总体分布本身的方差要低，这也意味着样本均值比单个观察值更可能接近于。


! Want to help?
 利用实验可视化二项分布：the Bean Machine 

让我们来完成这个伟大的视频（链接到YouTube上查看原始的完整的视频）显示了Bean机器的模拟。Bean机器由Francis Galton发明，以证明中心极限定理（特别是正态分布近似于二项分布）。这个想法是在一个装有等间距的格子的板子表面，将一个小小的球滚落下来。在这种情况下，他们左右碰撞（随机，独立）并且被收集到底部的一球宽的箱子中。随着时间的推移，箱子中的球柱的高度近似于钟形曲线。播放这个视频，看到这惊人的一幕发生在你的眼前。这个实验使我们对中心极限定理有了一个认识。样本均值的表现就像球在板面上反弹一样：有时往左反弹，有时往右反弹，但平均而言，它落在中间，结果就形成了钟形。

! 你需要记住什么和下一步？ 

这是一个长且密集的章节。你必须记住总体参数，样本均值的概念，最重要的是中心极限定理背后的概念（就是当你从总体中抽样时，这些样本的分布接近正态分布，这与总体本身的分布无关）。最后，请记住，收敛速度与样本大小的平方根成正比。


